---
title: 02. Information Theory
author: Tao He
date: 2019-04-29
category: Jekyll
layout: post
---

## 2.1 Entropy

long contents .....

1. a
2. b
3. c
4. d

## 2.2 Properties of Entropy

long contents .....

- 1
- 2
- 3
- 4

## 2.3 Cross Entropy Loss

long contents .....

1. e
2. f
3. g
4. h

## 2.4 Jointly Distributed Random Variables

### 2.4.1 Joint Entropy
> 결합 엔트로피(Joint Entropy)란?

결합 엔트로피 H(X1,X2)는 두 확률 변수 X1,X2​가 동시에 가질 정보량의 기대값이다.


$$
H(X_1, X_2) = \mathbb{E} \left[ \log \frac{1}{p_{X_1,X_2}(X_1,X_2)} \right] = \sum_{x_1,x_2} p_{X_1,X_2}(x_1,x_2) \log \frac{1}{p_{X_1,X_2}(x_1,x_2)}
$$

Thm. 30(Property of Entropy)

만약 $X_1$과 $X_2$가 독립이면 $H(X_1, X_2) = H(X_1) + H(X_2)$ 이다.

*Proof.*

$$
\begin{aligned}
H(X_1,X_2) &= \sum_{x_1,x_2} p_{X_1,X_2}(x_1,x_2) \log \frac{1}{p_{X_1}(x_1)p_{X_2}(x_2)} \\
&= \sum_{x_1,x_2} p_{X_1,X_2}(x_1,x_2) \left( \log \frac{1}{p_{X_1}(x_1)} + \log \frac{1}{p_{X_2}(x_2)} \right) \\
&= \sum_{x_1} p_{X_1}(x_1) \log \frac{1}{p_{X_1}(x_1)} + \sum_{x_2} p_{X_2}(x_2) \log \frac{1}{p_{X_2}(x_2)} \\
&= H(X_1) + H(X_2)
\end{aligned}
$$


$\therefore$ 두 변수가 독립인 경우 두 변수에서 얻는 정보량은 각 변수에서 얻는 정보량의 합으로 계산

만약 X1​과 X2가 강하게 상관되어 있다면, (X1,X2)로부터 얻는 정보량은 X1​으로부터 얻는 정보량과 거의 비슷할 것이다.

---

**Exercise 32**
> 만약 $H(X_1, X_2) = H(X_1) + H(X_2)$이면, 이것이 독립을 의미하는가?

**Exercise 33**

Alice가 $X$를 균등분포로 $\{1, 2, \dots, 8\}$ 중에서 뽑고, Bob이 세 가지 Yes or No 질문을 한다.
1) $X \in \{5, 6, 7, 8\}$ 인가?
2) $X \in \{1, 2, 5, 6\}$ 인가?
3) $X \in \{1, 3, 5, 7\}$ 인가?

 $$ Y_i = \begin{cases} 1 & \text{예} \\ 0 & \text{아니오} \end{cases} $$


각 $Y_i$는 베르누이 확률 변수이고, 서로 독립이다.

$$
H(Y_1) = H(Y_2) = H(Y_3) = 1
$$

$$
H(Y_1, Y_2, Y_3) = H(Y_1) + H(Y_2) + H(Y_3) = 3
$$

$$
H(X) = \log_2 8 = 3
$$

$\therefore$ 세 질문으로 \(X\)를 완벽하게 구분할 수 있음.


### 2.4.2 Conditional Entropy

>**Conditonal Entropy란?**

이미 알고 있는 정보가 존재할 때, 추가로 모르는 정보가 주는 정보량이다.

이미 알고 있는 정보 $Y$가 주어졌을 때, $X$에 관한 정보량은 $$H(X|Y)$$와 같이 나타내고 아래와 같이 정의된다.

$$
H(X|Y) = \mathbb{E}\Big[\log \frac{1}{p_{X|Y}(X|Y)}\Big]
= \sum_{x,y} p_{X,Y}(x,y) \log \frac{1}{p_{X|Y}(x|y)}.
$$

위의 경우에서 우리가 기댓값을 계산하고자 하는 함수는 $\log \frac{1}{p_{X|Y}(X|Y)}$이며 $x$ ,$y$의 확률은 joint distribution $p_{X,Y}(X,Y)$로 나타낼 수 있다.

우리는 기대값을 계산하기 위해 변수 $X$와 $Y$를 고려하고 있다. 결합 엔트로피(joint entropy)는 개별 엔트로피의 합이며, 각각의 $y$와 전체 엔트로피에 대한 각각의 기여(contribution)를 고려할 때 명확해진다. 특정 조건 y를 고정하는 경우를 생각해 보면 다음과 같이 나타낼 수 있다.

$$
H(X|Y = y) = \mathbb{E}\Big[ \log \frac{1}{p_{X|Y}(X|Y = y)} \Big]
$$

이제 위 수식에서 $X$만이 유일한 변수이다. 그러므로 위 수식을 다음과 같이 나타낼 수 있다.

$$
= \sum_{x} p_{X|Y}(x|y) \log \frac{1}{p_{X|Y}(x|y)}
$$

만약 우리가 특정 조건 $y$에 대한 모든 가능한 조건부 엔트로피를 합하면, $Y$에 주어진 $X$의 전체 조건부 엔트로피를 다음과 같이 나타낼 수 있다

$$
H(X|Y) = \sum_{y} p_Y(y) H(X|Y = y)
$$

이제 엔트로피 $H(X)$와 $H(Y|X)$를 고려해보자. $H(X)$는 $X$에 대한 정보이고, $H(Y|X)$는 $X$의 정보가 주어졌을 때 $H(X,Y)$에서의 '남은'정보이다. 따라서 우리는 $H(X) + H(Y|X) = H(X,Y)$라고 기대할 수 있고 아래와 같이 증명가능하다.

$$
\mathbb{E}\Big[ \log \frac{1}{p_X(X)} \Big]+ \mathbb{E}\Big[ \log \frac{1}{p_{Y|X}(Y|X)} \Big]= \mathbb{E}\Big[ \log \frac{1}{p_X(X) p_{Y|X}(Y|X)} \Big]
$$

$$
= \mathbb{E}\Big[ \log \frac{1}{p_{X,Y}(X,Y)} \Big]
$$
$$
= H(X,Y).
$$

$p_{Y|X}(Y|X) = \frac{p_{X,Y}(X,Y)}{p_X(X)}$
를 이용하면 위 증명이 성립함을 쉽게 알 수 있다.

**Exercise 35. 위의 추론 게임(guess game)에서 다음을 계산하여라**
 1. $H(Y2|Y1)$
 2. $H(Y4|Y1)$

풀이:

1.
$\mathbb{E}\Big[ \log \frac{1}{p_{Y2|Y1}(Y2|Y1)} \Big]$을 구하면 된다. 

이 경우에서는 $Y1$과 $Y2$가 독립이므로 $\mathbb{E}\Big[ \log \frac{1}{p_{Y2}(Y2)} \Big]$를 구하면 된다. 

즉, $\sum_{y} p_{Y2}(y) \log \frac{1}{p_{Y2}(y)}$를 계산하면 된다.

답: 1

2.

$p_{}(Y4=0|Y1=0) = 3/4$

$p_{}(Y4=1|Y1=0) = 1/4$

$p_{}(Y4=0|Y1=1) = 1/4$

$p_{}(Y4=1|Y1=1) = 3/4$

를 이용하면 $H(Y4|Y1=0)$은 $3/4\log4/3+1/4\log4$이고

$H(Y4|Y1=1)$은 $3/4\log4/3+1/4\log4$이다.

따라서 $H(Y4|Y1)$은 ($1/2$)($3/4\log4/3+1/4\log4$)+($1/2$) ($3/4\log4/3+1/4\log4$)이다.

이를 $H(Y4)=1$와 비교해보면 더 작은 것을 알 수 있다. 

따라서 조건이 존재할 경우 정보가 같거나 줄어든다는 사실을 알 수 있다.


### 2.4.3 Mutual Information

![alt text](image.png)

>**상호 정보량(Mutual Information)이란?**

상호 정보량은 엔트로피와 조건부 엔트로피의 차이로 정의된다.

$$
I(X; Y) = H(X) - H(X \mid Y), \quad I(Y; X) = H(Y) - H(Y \mid X)
$$

조건부 엔트로피와 상호 정보량의 관계는 위와 같은 도식으로도 표현 가능하다.
특히 $I(X; X)$의 경우 아래와 같이 계산되며, 결과적으로 $H(X)$와 같다.

$$
\begin{align*}
I(X; X) &= H(X) - H(X \mid X) \\
        &= H(X)
\end{align*}
$$

---

만약 $X$와 $Y$가 서로 **독립**이라면, 위 도식 혹은 정의에 의해  $$I(X; Y) = 0$$임을 보일 수 있다.  
또한, $I(X; Y) = 0$이면 $X$와 $Y$는 독립이다.

상호 정보량은 다음과 같이 **KL divergence**로도 표현된다.

$$
I(X; Y) = D(p_{X,Y} \parallel p_X p_Y)
$$

위 식에서 볼 수 있듯이, 상호 정보량은 두 확률 분포 간의 거리 또는 발산 정도를 의미한다.
$I(X; Y) = 0$이라면, $p_{X,Y} = p_X p_Y$가 되어 $X$와 $Y$는 독립이 된다.

### 2.4.4 Properties of Mutual Information

### 2.4.5 Conditional Mutual Information

## 2.5 Random Process

> **확률 과정(Random Process)이란?**

확률 과정은 다음과 같이 정의됩니다:

$$
X = \{X_n\}_{n=1}^{\infty}
$$

이것은 순서를 가진 확률 변수들의 집합이며, 각 $X_n$은 특정 확률 분포를 따릅니다.

- 여기서 $n$은 꼭 시간(time)을 의미하지 않아도 됩니다.
- 예시:
  - 텍스트: $X_1$은 첫 번째 문자, $X_2$는 두 번째 문자 등
  - 이미지: $X_{i,j}$는 $i$행 $j$열 픽셀의 밝기
  - 시계열: $X_t$는 $t$초 후의 값

**핵심**: 인덱스가 시간일 필요는 없으며, **순서만 있으면 확률 과정**이 됩니다.

---

**i.i.d. 과정이란?**

i.i.d.는 independent and identically distributed의 약자입니다.

- **독립(independent)**: 각 $X_n$이 서로 영향을 주지 않음
- **동일 분포(identically distributed)**: 모든 $X_n$이 동일한 확률 분포를 따름

전체 확률은 다음처럼 단순 곱으로 계산할 수 있습니다:

$$
P(X_1 = x_1, \dots, X_n = x_n) = \prod_{i=1}^{n} P(X_i = x_i)
$$

---

> [!warning] **현실은 대부분 i.i.d.가 아님**
> 예: 텍스트
>
> - "progra_ing"이라는 단어에서 빈칸에 'm'이 올 가능성이 높다고 판단할 수 있음
> - 이는 앞뒤 문맥이 영향을 주기 때문 → 요소들 간에 **의존성 존재**
>
> $\therefore$ 현실의 데이터는 보통 독립적이지 않고, 앞뒤 요소에 영향을 받습니다.

i.i.d.가 아닌 경우 사용하는 모델들:

- 마르코프 모델 (Markov Model)
- 순환 신경망 (Recurrent Neural Network, RNN)
- 트랜스포머 (Transformer)

### 2.5.1 What is Markovian?

i.i.d. ←────────────|────────────→ Practical  
**1st-order Markov**

**1차 마르코프 체인(first-order Markov chain)의 개념은, i.i.d. 가정과 실제 현실에서의 데이터 구조 사이를 연결해주는 중간 다리 역할을 합니다.**  
"마르코프(Markov)"라는 말은 **1차 상관성(first-order correlation)**이 있다는 의미입니다.  
즉, 현재 상태는 **직전 상태에만 의존**하고, 그 이전의 상태에는 의존하지 않는다는 것입니다.

---

**예제 41: 랜덤 워크(Random Walk)**

확률 과정 $X = \{X_n\}$를 다음과 같이 정의합니다:

초기 상태:

$$
X_0 = 0
$$

이후 각 $n$에 대해:

$$
X_n =
\begin{cases}
X_{n-1} + 1 & \text{with probability } \frac{1}{2} \\
X_{n-1} - 1 & \text{with probability } \frac{1}{2}
\end{cases}
$$

즉, 현재 위치에서 매 스텝마다 동전 던지기로 1만큼 앞 또는 뒤로 이동하는 무작위 행보입니다.

예를 들어 다음과 같은 정보가 주어졌다고 해 봅시다:

$$
X_{101} = 51
$$

이때 $X_{102}$는 다음 두 가지 중 하나입니다:

- $X_{102} = 50$
- $X_{102} = 52$

추가로 $X_{100} = 50$이라는 정보를 안다고 해도,  
$X_{102}$가 어떻게 될지를 예측하는 데 **아무런 도움이 되지 않습니다.**

이것은 **1차 마르코프 체인의 특성**과 정확히 일치합니다:

> **미래 상태는 현재 상태에만 의존하며, 과거는 무시됩니다.**

---

**핵심 요약**

| 구분           | 설명                                                             |
| -------------- | ---------------------------------------------------------------- |
| i.i.d.         | 각 값이 서로 독립이고 동일한 분포를 가짐                         |
| 1차 마르코프   | 현재 상태는 바로 직전 상태에만 의존함                            |
| 현실 데이터    | 대부분 i.i.d.는 아니며, 1차 마르코프 모델이 더 현실적            |
| 랜덤 워크 예시 | $X_{n}$은 $X_{n-1}$만으로 결정되며, $X_{n-2}$는 영향을 주지 않음 |

---

**요약 구조**

i.i.d. ←────────────|────────────→ 현실 데이터  
          ↑  
        1st-order Markov  
   (현재 상태는 직전 상태에만 의존)

### 2.5.2 1st Order Markov Process

### 2.5.3 kth Order Markov Process

확률 과정 X에 대해,
$$
P_{X_i | X^{i-1}}(x_i \mid x^{i-1}) = P_{X_i | X_{i-k}^{i-1}}(x_i \mid x_{i-k}^{i-1}),
$$
이 성립하는 시퀀스는 **k차 마르코프 과정(kth Order Markov Process)**를 따릅니다.

즉, k차 마르코프 과정을 따르는 시퀀스에 대해서
$$
P_{X^n}(x^n) = \prod_{i=1}^{n} P_{X_i \mid X_{i-k}^{i-1}}(x_i \mid x_{i-k}^{i-1})
$$
이 성립합니다.

### 2.5.4 Stationary Distribution

### 2.5.5 Stationary Markov Process

## 2.6 Continuous Random Variables

### 2.6.1 Probability Density Function

### 2.6.2 Gaussian

### 2.6.3 Differential Entropy

### 2.6.4 Properties of Differential Entropy

### 2.6.5 Joint Differential Entropy

### 2.6.6 Maximum Differential Entropy
