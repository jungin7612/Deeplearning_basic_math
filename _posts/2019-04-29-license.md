---
title: 02. Information Theory
author: Tao He
date: 2019-04-29
category: Jekyll
layout: post
---

## 2.1 Entropy

long contents .....

1. a
2. b
3. c
4. d

## 2.2 Properties of Entropy

long contents .....

- 1
- 2
- 3
- 4

## 2.3 Cross Entropy Loss

long contents .....

1. e
2. f
3. g
4. h

## 2.4 Jointly Distributed Random Variables

### 2.4.1 Joint Entropy

### 2.4.2 Conditional Entropy

>**Conditonal Entropy란?**

이미 알고 있는 정보가 존재할 때, 추가로 모르는 정보가 주는 정보량이다.

이미 알고 있는 정보 $Y$가 주어졌을 때, $X$에 관한 정보량은 $$H(X|Y)$$와 같이 나타내고 아래와 같이 정의된다.

$$
H(X|Y) = \mathbb{E}\Big[\log \frac{1}{p_{X|Y}(X|Y)}\Big]
= \sum_{x,y} p_{X,Y}(x,y) \log \frac{1}{p_{X|Y}(x|y)}.
$$

위의 경우에서 우리가 기댓값을 계산하고자 하는 함수는 $\log \frac{1}{p_{X|Y}(X|Y)}$이며 $x$ ,$y$의 확률은 joint distribution $p_{X,Y}(X,Y)$로 나타낼 수 있다.

우리는 기대값을 계산하기 위해 변수 $X$와 $Y$를 고려하고 있다. 결합 엔트로피(joint entropy)는 개별 엔트로피의 합이며, 각각의 $y$와 전체 엔트로피에 대한 각각의 기여(contribution)를 고려할 때 명확해진다. 특정 조건 y를 고정하는 경우를 생각해 보면 다음과 같이 나타낼 수 있다.

$$
H(X|Y = y) = \mathbb{E}\Big[ \log \frac{1}{p_{X|Y}(X|Y = y)} \Big]
$$

이제 위 수식에서 $X$만이 유일한 변수이다. 그러므로 위 수식을 다음과 같이 나타낼 수 있다.

$$

= \sum_{x} p_{X|Y}(x|y) \log \frac{1}{p_{X|Y}(x|y)}

$$

만약 우리가 특정 조건 $y$에 대한 모든 가능한 조건부 엔트로피를 합하면, $Y$에 주어진 $X$의 전체 조건부 엔트로피를 다음과 같이 나타낼 수 있다

$$
H(X|Y) = \sum_{y} p_Y(y) H(X|Y = y)
$$

이제 엔트로피 $H(X)$와 $H(Y|X)$를 고려해보자. $H(X)$는 $X$에 대한 정보이고, $H(Y|X)$는 $X$의 정보가 주어졌을 때 $H(X,Y)$에서의 '남은'정보이다. 따라서 우리는 $H(X) + H(Y|X) = H(X,Y)$라고 기대할 수 있고 아래와 같이 증명가능하다.

$$
\mathbb{E}\Big[ \log \frac{1}{p_X(X)} \Big]
+ \mathbb{E}\Big[ \log \frac{1}{p_{Y|X}(Y|X)} \Big]
= \mathbb{E}\Big[ \log \frac{1}{p_X(X) p_{Y|X}(Y|X)} \Big]
$$

$$
= \mathbb{E}\Big[ \log \frac{1}{p_{X,Y}(X,Y)} \Big]
$$
$$
= H(X,Y).
$$

$p_{Y|X}(Y|X) = \frac{p_{X,Y}(X,Y)}{p_X(X)}$
를 이용하면 위 증명이 성립함을 쉽게 알 수 있다.

**Exercise 35. 위의 추론 게임(guess game)에서 다음을 계산하여라**
 1. $H(Y2|Y1)$
 2. $H(Y4|Y1)$

풀이:

1.
$\mathbb{E}\Big[ \log \frac{1}{p_{Y2|Y1}(Y2|Y1)} \Big]$을 구하면 된다. 

이 경우에서는 $Y1$과 $Y2$가 독립이므로 $\mathbb{E}\Big[ \log \frac{1}{p_{Y2}(Y2)} \Big]$를 구하면 된다. 

즉, $\sum_{y} p_{Y2}(y) \log \frac{1}{p_{Y2}(y)}$를 계산하면 된다.

답: 1

2.

$p_(Y4=0|Y1=0) = 3/4$

$p_(Y4=1|Y1=0) = 1/4$

$p_(Y4=0|Y1=1) = 1/4$

$p_(Y4=1|Y1=1) = 3/4$

를 이용하면 $H(Y4|Y1=0)$은 $3/4\log4/3+1/4\log4$이고

$H(Y4|Y1=1)$은 $3/4\log4/3+1/4\log4$이다.

따라서 $H(Y4|Y1)$은 $1/2*3/4\log4/3+1/4\log4$+$1/2*3/4\log4/3+1/4\log4$이다.

이를 $H(Y4)=1$와 비교해보면 더 작은 것을 알 수 있다. 

따라서 조건이 존재할 경우 정보가 같거나 줄어든다는 사실을 알 수 있다.


### 2.4.3 Mutual Information

### 2.4.4 Properties of Mutual Information

### 2.4.5 Conditional Mutual Information

## 2.5 Random Process

> **확률 과정(Random Process)이란?**

확률 과정은 다음과 같이 정의됩니다:

$$
X = \{X_n\}_{n=1}^{\infty}
$$

이것은 순서를 가진 확률 변수들의 집합이며, 각 $X_n$은 특정 확률 분포를 따릅니다.

- 여기서 $n$은 꼭 시간(time)을 의미하지 않아도 됩니다.
- 예시:
  - 텍스트: $X_1$은 첫 번째 문자, $X_2$는 두 번째 문자 등
  - 이미지: $X_{i,j}$는 $i$행 $j$열 픽셀의 밝기
  - 시계열: $X_t$는 $t$초 후의 값

**핵심**: 인덱스가 시간일 필요는 없으며, **순서만 있으면 확률 과정**이 됩니다.

---

**i.i.d. 과정이란?**

i.i.d.는 independent and identically distributed의 약자입니다.

- **독립(independent)**: 각 $X_n$이 서로 영향을 주지 않음
- **동일 분포(identically distributed)**: 모든 $X_n$이 동일한 확률 분포를 따름

전체 확률은 다음처럼 단순 곱으로 계산할 수 있습니다:

$$
P(X_1 = x_1, \dots, X_n = x_n) = \prod_{i=1}^{n} P(X_i = x_i)
$$

---

> [!warning] **현실은 대부분 i.i.d.가 아님**
> 예: 텍스트
>
> - "progra_ing"이라는 단어에서 빈칸에 'm'이 올 가능성이 높다고 판단할 수 있음
> - 이는 앞뒤 문맥이 영향을 주기 때문 → 요소들 간에 **의존성 존재**
>
> $\therefore$ 현실의 데이터는 보통 독립적이지 않고, 앞뒤 요소에 영향을 받습니다.

i.i.d.가 아닌 경우 사용하는 모델들:

- 마르코프 모델 (Markov Model)
- 순환 신경망 (Recurrent Neural Network, RNN)
- 트랜스포머 (Transformer)

### 2.5.1 What is Markovian?

i.i.d. ←────────────|────────────→ Practical  
**1st-order Markov**

**1차 마르코프 체인(first-order Markov chain)의 개념은, i.i.d. 가정과 실제 현실에서의 데이터 구조 사이를 연결해주는 중간 다리 역할을 합니다.**  
"마르코프(Markov)"라는 말은 **1차 상관성(first-order correlation)**이 있다는 의미입니다.  
즉, 현재 상태는 **직전 상태에만 의존**하고, 그 이전의 상태에는 의존하지 않는다는 것입니다.

---

**예제 41: 랜덤 워크(Random Walk)**

확률 과정 $X = \{X_n\}$를 다음과 같이 정의합니다:

초기 상태:

$$
X_0 = 0
$$

이후 각 $n$에 대해:

$$
X_n =
\begin{cases}
X_{n-1} + 1 & \text{with probability } \frac{1}{2} \\
X_{n-1} - 1 & \text{with probability } \frac{1}{2}
\end{cases}
$$

즉, 현재 위치에서 매 스텝마다 동전 던지기로 1만큼 앞 또는 뒤로 이동하는 무작위 행보입니다.

예를 들어 다음과 같은 정보가 주어졌다고 해 봅시다:

$$
X_{101} = 51
$$

이때 $X_{102}$는 다음 두 가지 중 하나입니다:

- $X_{102} = 50$
- $X_{102} = 52$

추가로 $X_{100} = 50$이라는 정보를 안다고 해도,  
$X_{102}$가 어떻게 될지를 예측하는 데 **아무런 도움이 되지 않습니다.**

이것은 **1차 마르코프 체인의 특성**과 정확히 일치합니다:

> **미래 상태는 현재 상태에만 의존하며, 과거는 무시됩니다.**

---

**핵심 요약**

| 구분           | 설명                                                             |
| -------------- | ---------------------------------------------------------------- |
| i.i.d.         | 각 값이 서로 독립이고 동일한 분포를 가짐                         |
| 1차 마르코프   | 현재 상태는 바로 직전 상태에만 의존함                            |
| 현실 데이터    | 대부분 i.i.d.는 아니며, 1차 마르코프 모델이 더 현실적            |
| 랜덤 워크 예시 | $X_{n}$은 $X_{n-1}$만으로 결정되며, $X_{n-2}$는 영향을 주지 않음 |

---

**요약 구조**

i.i.d. ←────────────|────────────→ 현실 데이터  
          ↑  
        1st-order Markov  
   (현재 상태는 직전 상태에만 의존)

### 2.5.2 1st Order Markov Process

### 2.5.3 kth Order Markov Process

### 2.5.4 Stationary Distribution

### 2.5.5 Stationary Markov Process

## 2.6 Continuous Random Variables

### 2.6.1 Probability Density Function

### 2.6.2 Gaussian

### 2.6.3 Differential Entropy

### 2.6.4 Properties of Differential Entropy

### 2.6.5 Joint Differential Entropy

### 2.6.6 Maximum Differential Entropy
