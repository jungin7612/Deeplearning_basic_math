---
title: 02. Information Theory
author: Tao He
date: 2019-04-29
category: Jekyll
layout: post
---

## 2.1 Entropy

long contents .....

1. a
2. b
3. c
4. d

## 2.2 Properties of Entropy

long contents .....

- 1
- 2
- 3
- 4

## 2.3 Cross Entropy Loss

long contents .....

1. e
2. f
3. g
4. h

## 2.4 Jointly Distributed Random Variables

### 2.4.1 Joint Entropy
> 결합 엔트로피(Joint Entropy)란?

결합 엔트로피 H(X1,X2)는 두 확률 변수 X1,X2​가 동시에 가질 정보량의 기대값이다.


$$
H(X_1, X_2) = \mathbb{E} \left[ \log \frac{1}{p_{X_1,X_2}(X_1,X_2)} \right] = \sum_{x_1,x_2} p_{X_1,X_2}(x_1,x_2) \log \frac{1}{p_{X_1,X_2}(x_1,x_2)}
$$

Thm. 30(Property of Entropy)

만약 $X_1$과 $X_2$가 독립이면 $H(X_1, X_2) = H(X_1) + H(X_2)$ 이다.

*Proof.*

$$
\begin{aligned}
H(X_1,X_2) &= \sum_{x_1,x_2} p_{X_1,X_2}(x_1,x_2) \log \frac{1}{p_{X_1}(x_1)p_{X_2}(x_2)} \\
&= \sum_{x_1,x_2} p_{X_1,X_2}(x_1,x_2) \left( \log \frac{1}{p_{X_1}(x_1)} + \log \frac{1}{p_{X_2}(x_2)} \right) \\
&= \sum_{x_1} p_{X_1}(x_1) \log \frac{1}{p_{X_1}(x_1)} + \sum_{x_2} p_{X_2}(x_2) \log \frac{1}{p_{X_2}(x_2)} \\
&= H(X_1) + H(X_2)
\end{aligned}
$$


$\therefore$ 두 변수가 독립인 경우 두 변수에서 얻는 정보량은 각 변수에서 얻는 정보량의 합으로 계산

만약 X1​과 X2가 강하게 상관되어 있다면, (X1,X2)로부터 얻는 정보량은 X1​으로부터 얻는 정보량과 거의 비슷할 것이다.

---

**Exercise 32**
> 만약 $H(X_1, X_2) = H(X_1) + H(X_2)$이면, 이것이 독립을 의미하는가?

**Exercise 33**

Alice가 $X$를 균등분포로 $\{1, 2, \dots, 8\}$ 중에서 뽑고, Bob이 세 가지 Yes or No 질문을 한다.
1) $X \in \{5, 6, 7, 8\}$ 인가?
2) $X \in \{1, 2, 5, 6\}$ 인가?
3) $X \in \{1, 3, 5, 7\}$ 인가?

 $$ Y_i = \begin{cases} 1 & \text{예} \\ 0 & \text{아니오} \end{cases} $$


각 $Y_i$는 베르누이 확률 변수이고, 서로 독립이다.

$$
H(Y_1) = H(Y_2) = H(Y_3) = 1
$$

$$
H(Y_1, Y_2, Y_3) = H(Y_1) + H(Y_2) + H(Y_3) = 3
$$

$$
H(X) = \log_2 8 = 3
$$

$\therefore$ 세 질문으로 \(X\)를 완벽하게 구분할 수 있음.


### 2.4.2 Conditional Entropy

>**Conditonal Entropy란?**

이미 알고 있는 정보가 존재할 때, 추가로 모르는 정보가 주는 정보량이다.

이미 알고 있는 정보 $Y$가 주어졌을 때, $X$에 관한 정보량은 $$H(X|Y)$$와 같이 나타내고 아래와 같이 정의된다.

$$
H(X|Y) = \mathbb{E}\Big[\log \frac{1}{p_{X|Y}(X|Y)}\Big]
= \sum_{x,y} p_{X,Y}(x,y) \log \frac{1}{p_{X|Y}(x|y)}.
$$

위의 경우에서 우리가 기댓값을 계산하고자 하는 함수는 $\log \frac{1}{p_{X|Y}(X|Y)}$이며 $x$ ,$y$의 확률은 joint distribution $p_{X,Y}(X,Y)$로 나타낼 수 있다.

우리는 기대값을 계산하기 위해 변수 $X$와 $Y$를 고려하고 있다. 결합 엔트로피(joint entropy)는 개별 엔트로피의 합이며, 각각의 $y$와 전체 엔트로피에 대한 각각의 기여(contribution)를 고려할 때 명확해진다. 특정 조건 y를 고정하는 경우를 생각해 보면 다음과 같이 나타낼 수 있다.

$$
H(X|Y = y) = \mathbb{E}\Big[ \log \frac{1}{p_{X|Y}(X|Y = y)} \Big]
$$

이제 위 수식에서 $X$만이 유일한 변수이다. 그러므로 위 수식을 다음과 같이 나타낼 수 있다.

$$
= \sum_{x} p_{X|Y}(x|y) \log \frac{1}{p_{X|Y}(x|y)}
$$

만약 우리가 특정 조건 $y$에 대한 모든 가능한 조건부 엔트로피를 합하면, $Y$에 주어진 $X$의 전체 조건부 엔트로피를 다음과 같이 나타낼 수 있다

$$
H(X|Y) = \sum_{y} p_Y(y) H(X|Y = y)
$$

이제 엔트로피 $H(X)$와 $H(Y|X)$를 고려해보자. $H(X)$는 $X$에 대한 정보이고, $H(Y|X)$는 $X$의 정보가 주어졌을 때 $H(X,Y)$에서의 '남은'정보이다. 따라서 우리는 $H(X) + H(Y|X) = H(X,Y)$라고 기대할 수 있고 아래와 같이 증명가능하다.

$$
\mathbb{E}\Big[ \log \frac{1}{p_X(X)} \Big]+ \mathbb{E}\Big[ \log \frac{1}{p_{Y|X}(Y|X)} \Big]= \mathbb{E}\Big[ \log \frac{1}{p_X(X) p_{Y|X}(Y|X)} \Big]
$$

$$
= \mathbb{E}\Big[ \log \frac{1}{p_{X,Y}(X,Y)} \Big]
$$
$$
= H(X,Y).
$$

$p_{Y|X}(Y|X) = \frac{p_{X,Y}(X,Y)}{p_X(X)}$
를 이용하면 위 증명이 성립함을 쉽게 알 수 있다.

**Exercise 35. 위의 추론 게임(guess game)에서 다음을 계산하여라**
 1. $H(Y2|Y1)$
 2. $H(Y4|Y1)$

풀이:

1.
$\mathbb{E}\Big[ \log \frac{1}{p_{Y2|Y1}(Y2|Y1)} \Big]$을 구하면 된다. 

이 경우에서는 $Y1$과 $Y2$가 독립이므로 $\mathbb{E}\Big[ \log \frac{1}{p_{Y2}(Y2)} \Big]$를 구하면 된다. 

즉, $\sum_{y} p_{Y2}(y) \log \frac{1}{p_{Y2}(y)}$를 계산하면 된다.

답: 1

2.

$p_{}(Y4=0|Y1=0) = 3/4$

$p_{}(Y4=1|Y1=0) = 1/4$

$p_{}(Y4=0|Y1=1) = 1/4$

$p_{}(Y4=1|Y1=1) = 3/4$

를 이용하면 $H(Y4|Y1=0)$은 $3/4\log4/3+1/4\log4$이고

$H(Y4|Y1=1)$은 $3/4\log4/3+1/4\log4$이다.

따라서 $H(Y4|Y1)$은 ($1/2$)($3/4\log4/3+1/4\log4$)+($1/2$) ($3/4\log4/3+1/4\log4$)이다.

이를 $H(Y4)=1$와 비교해보면 더 작은 것을 알 수 있다. 

따라서 조건이 존재할 경우 정보가 같거나 줄어든다는 사실을 알 수 있다.


### 2.4.3 Mutual Information

### 2.4.4 Properties of Mutual Information
# 2.4.4 상호정보량의 성질

## 정리 36 (데이터 처리 부등식 I)  
**정리.** f가 결정론적 함수라면,  
H(X) ≥ H(f(X)) 이다.

**증명.**  
H(X, f(X)) = H(X) + H(f(X) | X) = H(X)  (식 80–81)  
또한  
H(X, f(X)) = H(f(X)) + H(X | f(X)) ≥ H(f(X))  (식 82–83)  
따라서 H(X) ≥ H(f(X)).  
(f가 일대일 대응이고 전사이면 역함수가 존재하므로 이 경우에는 H(X) = H(f(X)).)

---

## 정리 37 (Mutual information은 대칭적이다)  
**정리.**  
I(X;Y) = I(Y;X)

**증명.**  
위 정의들을 평문으로 쓰면 다음과 같다:
```
I(X;Y) = H(X) - H(X | Y)             (식 84)
       = H(X) - (H(X,Y) - H(Y))     (식 85)
       = H(X) + H(Y) - H(X,Y)       (식 86)
       = I(Y;X)                    (식 87)
```

---

## 정리 38 (Mutual information은 비음수이다)  
**정리.**  
I(X;Y) ≥ 0

**증명.**  
```
H(X) - H(X | Y)
= E[ log(1 / p_X(X)) ] - E[ log(1 / p_{X|Y}(X | Y)) ]         (식 88)
= E[ log( p_{X|Y}(X | Y) / p_X(X) ) ]                        (식 89)
= E[ log( p_{X,Y}(X,Y) / (p_X(X) p_Y(Y)) ) ]                (식 90)
= sum_{x,y} p_{X,Y}(x,y) * log( p_{X,Y}(x,y) / (p_X(x) p_Y(y)) )  (식 91)
= D( p_{X,Y} || p_X p_Y ) ≥ 0                                (식 92)
```
따라서 I(X;Y) = D( p_{X,Y} || p_X p_Y ) ≥ 0.  
여기서 p_X p_Y는 X와 Y가 각각 주변분포 p_X, p_Y를 가지지만 서로 독립인 (X,Y)에 대한 분포이다.  
또한 부등식 H(X) ≥ H(X | Y)는 “조건부를 취하면 불확실성이 줄어들거나 유지된다”는 해석을 가질 수 있다.

---

## 정리 39 (데이터 처리 부등식 II)  
**정리.** 임의의 함수 f: X → R에 대해 다음이 성립한다:  
I(X;Y) ≥ I(f(X);Y)

**증명.**  
```
I(X;Y) = H(Y) - H(Y | X)                       (식 93)
       = H(Y) - H(Y | X, f(X))                (식 94)
       ≥ H(Y) - H(Y | f(X))                   (식 95)
       = I(f(X);Y)                            (식 96)
```

**일반화.**  
X - Y - Z가 마르코프 체인(또는 X와 Z가 Y를 조건으로 주었을 때 조건부 독립)일 때, 다음이 서로 동치이다:

1. X - Y - Z ⟷ X와 Z가 Y를 주었을 때 독립 (즉, X ⟂ Z | Y) (식 97)  
2. Y가 알려져 있을 때 X는 Z를 추정하는 데 쓸모없다. (식 98)  
3. 모든 x,y,z에 대해 p_{Z|X,Y}(z | x,y) = p_{Z|Y}(z | y). (식 99)  

---

## 정리 40 (데이터 처리 부등식 III)  
**정리.**  
만약 X - Y - Z가 마르코프 체인을 이룬다면,  
I(X;Z) ≤ I(Y;Z)  
또는 대칭적으로 I(Z;X) ≤ I(Z;Y).

**증명.**  
```
I(Y;Z) = H(Z) - H(Z | Y)                          (식 100)
       = H(Z) - H(Z | X, Y)                      (식 101)
       ≥ H(Z) - H(Z | X)                         (식 102)
       = I(X;Z)                                  (식 103)
```
따라서 I(Y;Z) ≥ I(X;Z), 즉 I(Z;Y) ≥ I(Z;X)이다.

---

# 문제 29.(b)

## 문제 29.  
X, Y, Z가 결합 확률 분포를 가지는 임의의 확률 변수일 때, 다음 부등식을 증명하고 등호 성립 조건을 찾아라.  
**(b)** I(X, Y; Z) ≥ I(X; Z).

## 풀이

### 1. 체인 룰(chain rule) 적용  
상호 정보의 체인 룰에 따르면:  
I(X, Y; Z) = I(X; Z) + I(Y; Z | X).  
이는 “X, Y가 합쳐질 때 Z와 주고받는 정보량”을 먼저 X가 주는 정보량과, X를 알고 난 뒤 Y가 더 주는 추가 정보량으로 분해한 식이다.

### 2. 조건부 상호 정보의 비음성  
항상  
I(Y; Z | X) ≥ 0  
이다. (KL 발산 형태로 증명할 수 있다.)

### 3. 부등식 결론  
따라서  
I(X, Y; Z) = I(X; Z) + I(Y; Z | X) ≥ I(X; Z).

### 4. 등호 성립 조건  
등호 I(X, Y; Z) = I(X; Z)가 되려면  
I(Y; Z | X) = 0 ⟷ Y ⟂ Z | X  
이어야 한다.  
즉 “X를 조건으로 두었을 때 Y와 Z가 독립”이어야 한다.  
이 역시 Y → X → Z 형태의 마르코프 사슬과 동치이다.

---

# 문제 31

## 문제 31.  
임의의 결정론적 함수 g에 대하여,  
H(X | g(Y)) = H(X | Y)  
이 성립하려면 어떤 조건이 필요한가?

## 풀이

### 1. 데이터 처리 부등식 I (조건부 형태)  
이미 알고 있는 바:  
H(X | g(Y)) ≥ H(X | Y),  
왜냐하면 “Y를 알면 g(Y)를 알 수 있지만, g(Y)를 안다고 해서 항상 Y가 복원되지는 않으므로” 불확실성이 더 작아지거나 같기 때문이다.

### 2. 등호 조건 분석  
H(X | g(Y)) = H(X | Y) 일 때, 양쪽 사이에 끼어 있는  
H(X | Y) - H(X | g(Y)) = I(X;Y | g(Y)) = 0  
이다.  
즉, “g(Y)를 조건으로 X와 Y가 독립”이어야 한다.

### 3. 마르코프 사슬 해석  
I(X;Y | g(Y)) = 0 ⟷ X ⟂ Y | g(Y).  
이는 바로  
X → g(Y) → Y  
꼴의 마르코프 사슬 형태가 성립함을 뜻한다.

### 4. 특수 사례  
- g가 일대일 대응(가역)이면 당연히 g(Y) ↔ Y 양방향 복원이 가능하므로 등호 성립.  
- 또 X와 Y가 본래 독립이라도  
  H(X | g(Y)) = H(X) = H(X | Y)  
  이므로 등호가 된다.  
  이 두 경우는 포함되지만, **유일한 경우는 아니다.**

---

# 문제 42.(b)

## 문제 42.  
다음 부등식들 중 일반적으로 ≥, =, ≤ 중 어느 관계가 성립하는지 각각 표시하라.  
**(b)** I(g(X); Y) vs. I(X; Y).

## 풀이

### 1. 데이터 처리 부등식 II  
이것은 4.4절에서 나온 정리와 같다. 임의의 결정론적 함수 g에 대하여:  
I(g(X); Y) ≤ I(X; Y).

### 2. 직관  
- X가 Y에 갖는 정보량이 I(X;Y)이고,  
- X를 g로 가공한 g(X)는 X보다 “덜 상세”(또는 같음) →  
- g(X)가 Y에 제공할 수 있는 정보도 당연히 I(X;Y) 이하여야 한다.

### 3. 형식적 증명  
```
I(g(X); Y) = H(Y) - H(Y | g(X))
           ≤ H(Y) - H(Y | X)    (조건부 엔트로피 감소: H(Y | g(X)) ≥ H(Y | X))
           = I(X; Y)
```

### 4. 등호 성립 조건  
등호가 되려면  
H(Y | g(X)) = H(Y | X) ⟷ I(Y; X | g(X)) = 0 ⟷ Y ⟂ X | g(X).  
즉 “g(X)를 조건으로 X와 Y가 독립”일 때 등호가 된다.  
다시 말해 g(X)를 기준으로 X와 Y는 더 이상의 조건부 상호 정보가 없다.

### 2.4.5 Conditional Mutual Information

## 2.5 Random Process

> **확률 과정(Random Process)이란?**

확률 과정은 다음과 같이 정의됩니다:

$$
X = \{X_n\}_{n=1}^{\infty}
$$

이것은 순서를 가진 확률 변수들의 집합이며, 각 $X_n$은 특정 확률 분포를 따릅니다.

- 여기서 $n$은 꼭 시간(time)을 의미하지 않아도 됩니다.
- 예시:
  - 텍스트: $X_1$은 첫 번째 문자, $X_2$는 두 번째 문자 등
  - 이미지: $X_{i,j}$는 $i$행 $j$열 픽셀의 밝기
  - 시계열: $X_t$는 $t$초 후의 값

**핵심**: 인덱스가 시간일 필요는 없으며, **순서만 있으면 확률 과정**이 됩니다.

---

**i.i.d. 과정이란?**

i.i.d.는 independent and identically distributed의 약자입니다.

- **독립(independent)**: 각 $X_n$이 서로 영향을 주지 않음
- **동일 분포(identically distributed)**: 모든 $X_n$이 동일한 확률 분포를 따름

전체 확률은 다음처럼 단순 곱으로 계산할 수 있습니다:

$$
P(X_1 = x_1, \dots, X_n = x_n) = \prod_{i=1}^{n} P(X_i = x_i)
$$

---

> [!warning] **현실은 대부분 i.i.d.가 아님**
> 예: 텍스트
>
> - "progra_ing"이라는 단어에서 빈칸에 'm'이 올 가능성이 높다고 판단할 수 있음
> - 이는 앞뒤 문맥이 영향을 주기 때문 → 요소들 간에 **의존성 존재**
>
> $\therefore$ 현실의 데이터는 보통 독립적이지 않고, 앞뒤 요소에 영향을 받습니다.

i.i.d.가 아닌 경우 사용하는 모델들:

- 마르코프 모델 (Markov Model)
- 순환 신경망 (Recurrent Neural Network, RNN)
- 트랜스포머 (Transformer)

### 2.5.1 What is Markovian?

i.i.d. ←────────────|────────────→ Practical  
**1st-order Markov**

**1차 마르코프 체인(first-order Markov chain)의 개념은, i.i.d. 가정과 실제 현실에서의 데이터 구조 사이를 연결해주는 중간 다리 역할을 합니다.**  
"마르코프(Markov)"라는 말은 **1차 상관성(first-order correlation)**이 있다는 의미입니다.  
즉, 현재 상태는 **직전 상태에만 의존**하고, 그 이전의 상태에는 의존하지 않는다는 것입니다.

---

**예제 41: 랜덤 워크(Random Walk)**

확률 과정 $X = \{X_n\}$를 다음과 같이 정의합니다:

초기 상태:

$$
X_0 = 0
$$

이후 각 $n$에 대해:

$$
X_n =
\begin{cases}
X_{n-1} + 1 & \text{with probability } \frac{1}{2} \\
X_{n-1} - 1 & \text{with probability } \frac{1}{2}
\end{cases}
$$

즉, 현재 위치에서 매 스텝마다 동전 던지기로 1만큼 앞 또는 뒤로 이동하는 무작위 행보입니다.

예를 들어 다음과 같은 정보가 주어졌다고 해 봅시다:

$$
X_{101} = 51
$$

이때 $X_{102}$는 다음 두 가지 중 하나입니다:

- $X_{102} = 50$
- $X_{102} = 52$

추가로 $X_{100} = 50$이라는 정보를 안다고 해도,  
$X_{102}$가 어떻게 될지를 예측하는 데 **아무런 도움이 되지 않습니다.**

이것은 **1차 마르코프 체인의 특성**과 정확히 일치합니다:

> **미래 상태는 현재 상태에만 의존하며, 과거는 무시됩니다.**

---

**핵심 요약**

| 구분           | 설명                                                             |
| -------------- | ---------------------------------------------------------------- |
| i.i.d.         | 각 값이 서로 독립이고 동일한 분포를 가짐                         |
| 1차 마르코프   | 현재 상태는 바로 직전 상태에만 의존함                            |
| 현실 데이터    | 대부분 i.i.d.는 아니며, 1차 마르코프 모델이 더 현실적            |
| 랜덤 워크 예시 | $X_{n}$은 $X_{n-1}$만으로 결정되며, $X_{n-2}$는 영향을 주지 않음 |

---

**요약 구조**

i.i.d. ←────────────|────────────→ 현실 데이터  
          ↑  
        1st-order Markov  
   (현재 상태는 직전 상태에만 의존)

### 2.5.2 1st Order Markov Process

### 2.5.3 kth Order Markov Process

### 2.5.4 Stationary Distribution

### 2.5.5 Stationary Markov Process

## 2.6 Continuous Random Variables

### 2.6.1 Probability Density Function

### 2.6.2 Gaussian

### 2.6.3 Differential Entropy

### 2.6.4 Properties of Differential Entropy

### 2.6.5 Joint Differential Entropy

### 2.6.6 Maximum Differential Entropy
